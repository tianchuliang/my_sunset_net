{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''\n",
    "<script>\n",
    "code_show=false; \n",
    "function code_toggle() {\n",
    "    if (code_show){\n",
    "        $('div.input').show();\n",
    "    } else {\n",
    "        $('div.input').hide();\n",
    "    }\n",
    "    code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code\"></form>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Sunset Images by Fine Tuning CaffeNet (A minor variant of AlexNet)\n",
    "\n",
    "About finetuning CaffeNet:\n",
    "\n",
    "- My general strategy on finetuning is as follows:\n",
    "    \n",
    "    * For layers that inherit pretrained weights from CaffeNet, I set their lr_mult to be zero; this will make sure these layers inherit the weights and not change the weights during the fine tuning (training) process. This will also significantly reduces the training time since we don't update these weights and consequently no backward computation will be needed for these layers. \n",
    "    \n",
    "    * For layers that need to learn new weights and finetune particularly for the sunset dataset, I set their lr_mult to be nonzero; also, I need to change the layer names so that when the CaffeNet imports weights, it will not put weights to these layers. These layers will learn new weights from scratch particularly for the new sunset dataset. \n",
    "    \n",
    "    * Note that I could've set all layer's lr_mult to be nonzero and let all layers import weights; this means I fine tune all layers on top of pretrained weights. This may give a more suited model for sunset dataset, but it would probably consume longer computing time. Further more, limiting the finetuning layers to 2 or 3 layers already gave pretty good convergence rate and performance as I will show in the following sections. \n",
    "\n",
    "- To avoid shape mismatch error, I needed to be careful about InnerProduct layers in CaffeNet. In particular, n.fc6, n.fc7, n.fc8 are the last three InnerProduct layers in CaffeNet. To fine tune CaffeNet to classify Sunset images, I need to re-learn weights for these InnerProduct layers, and not just the very last on, n.fc8. This is because n.fc6, n.fc7 both depends on the input dimensions of new data, the sunset images. To make sure the fine tuned CaffeNet works without shape mismatch error, I have to tune weights on all three InnerProduct layers. \n",
    "\n",
    "- To do this, when I define the CaffeNet structure, I renamed both n.fc6 and n.fc8 to n.fc6_sunset and n.fc8_sunset; this tells CaffeNet to not inherit weights from the pretrained model. For some reason, I didn't need to rename n.fc7 and it didn't bring error. I am guessing this is because n.fc7 is taking output from n.fc6 and thus doesn't directly correspond to the new input data dimensions. The reason we must rename n.fc6 is that n.fc6 is sensitive to new data shapes; and the reason we must rename n.fc8 is because it is the last fully connected layer before loss, accuracy, and prob computation and we need to fine tune it according to the new sunset dataset. I set all last three InnerProduct layers to learn new weights (by setting lr_mult!=0) and let other layers inherit pretrained weights (n.fc7 will start with pretrained weights and will learn on the training process, whereas n.fc6 and n.fc8 learns weights totally from scratch).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sunset_helper\n",
    "import sunset_helper_aug\n",
    "import log_parser\n",
    "# import log_parser\n",
    "caffe_root = '/usr/local/caffe/'\n",
    "code_root='/Users/tianchuliang/Documents/Projects/my_sunset_net/my_sunset_net/code'\n",
    "data_root='/Users/tianchuliang/Documents/Projects/my_sunset_net/my_sunset_net/data'\n",
    "nets_root='/Users/tianchuliang/Documents/Projects/my_sunset_net/my_sunset_net/net'\n",
    "sunset_lmdb=data_root+\"/lmdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_net_path = sunset_helper.sunset_net(sunset_lmdb,50,train=True)\n",
    "test_net_path = sunset_helper.sunset_net(sunset_lmdb,50,train=False)\n",
    "sunset_solver_filename = sunset_helper.solver(train_net_path, test_net_path= test_net_path, \n",
    "                                             displayFreq=5,test_interval=5,stepsize=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on original sunset images\n",
    "\n",
    "The first model was trained on the original sunset images for 300 iterations, with batch size = 50; this is equivalent to about 50 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Solver: \", sunset_solver_filename\n",
    "print \"Train: \", train_net_path\n",
    "print \"Test: \", test_net_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solver prototxt file: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat /Users/tianchuliang/Documents/Projects/my_sunset_net/my_sunset_net/net/my_sunset_net_solver_cmdline.prototxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train prototxt file: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat /Users/tianchuliang/Documents/Projects/my_sunset_net/my_sunset_net/net/my_sunset_net_train_cmdline.prototxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test prototxt file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat /Users/tianchuliang/Documents/Projects/my_sunset_net/my_sunset_net/net/my_sunset_net_test_cmdline.prototxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, we can use Caffe's builtin parser to parse the log file into training and testing logs; I have written a small bash script ~/code/split_log_file.sh that executes the Caffe parser command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(code_root+'/bash')\n",
    "os.system('chmod +x split_log_file.sh')\n",
    "os.system('./split_log_file.sh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, with train.log and test.log, we can start plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_log_file = nets_root+'/my_sunset_net_cmdline.log.train'\n",
    "test_log_file = nets_root+'/my_sunset_net_cmdline.log.test'\n",
    "train_iters,train_loss,train_acc=log_parser.parse_train(train_log_file)\n",
    "test_iters,test_loss,test_acc=log_parser.parse_test(test_log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Training loss and accuracy over iterations')\n",
    "plt.xlabel('Number of iterations divided by 5')\n",
    "plt.ylabel('loss/accuracy')\n",
    "plt.plot(train_loss)\n",
    "plt.plot(train_acc)\n",
    "plt.legend(['Train loss','Train accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.title('Testing loss and accuracy over iterations')\n",
    "plt.xlabel('Number of iterations divided by 5')\n",
    "plt.ylabel('loss/accuracy')\n",
    "plt.plot(test_loss)\n",
    "plt.plot(test_acc)\n",
    "plt.legend(['Test loss','Test accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we can use the trained my_sunset_net model (300 iterations, approximately 30 epochs) to make predictions on the test lmdb and plot corresponding confusion matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstrate the network works using deploy.prototxt\n",
    "\n",
    "Below, I will deploy my trained my_sunset_net (trained for 30 epochs) using the deploy.prototxt, and test 5 random sunset images and 5 random nonsunset images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import caffe\n",
    "deployed_net = caffe.Net(nets_root+'/deploy.prototxt',nets_root+'/my_sunset_net_cmdline_iter_300.caffemodel'\n",
    "                        ,caffe.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Since we are using the deployed my_sunset_net, we need to load images directly \n",
    "# using cv2 the data folder:\n",
    "import cv2 \n",
    "import os \n",
    "import numpy as np\n",
    "pos_dat = data_root+'/Test/sunset'\n",
    "neg_dat = data_root+'/Test/nonsunset'\n",
    "false_pos = []\n",
    "false_neg = []\n",
    "labels = []\n",
    "pos_files = np.array(os.listdir(pos_dat))[np.random.choice(240,5,replace=False)]\n",
    "neg_files = np.array(os.listdir(neg_dat))[np.random.choice(240,5,replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Test on these sunset images: \", pos_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Test on these nonsunset images\", neg_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for pos_file in pos_files:\n",
    "    print '***Testing sunset images:***'\n",
    "    if pos_file == '.DS_Store':\n",
    "        continue\n",
    "    else:\n",
    "        labels.append(1)\n",
    "        img = cv2.imread(pos_dat+'/'+pos_file)\n",
    "        img = cv2.resize(img,(256,256))\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        in_ = np.array(img,dtype=np.float32)\n",
    "        in_ = in_[:,:,::-1]\n",
    "        in_ -= np.array((104.00698793,116.66876762,122.67891434))\n",
    "        in_ = in_.transpose((2,0,1))\n",
    "        deployed_net.blobs['data'].reshape(1, *in_.shape)\n",
    "        deployed_net.blobs['data'].data[...] = in_\n",
    "        deployed_net.forward()\n",
    "        out_probs = deployed_net.blobs['prob'].data[...]\n",
    "        out = out_probs[:,:].argmax(axis=1)\n",
    "        print 'Possible labels', out\n",
    "        dic = {1:'sunset',0:'nonsunset'}\n",
    "        print 'Classification result: ',dic[int(np.unique(out))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for neg_file in neg_files:\n",
    "    print '***Testing nonsunset images:***'\n",
    "    if neg_file == '.DS_Store':\n",
    "        continue\n",
    "    else:\n",
    "        labels.append(1)\n",
    "        img = cv2.imread(neg_dat+'/'+neg_file)\n",
    "        img = cv2.resize(img,(256,256))\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        in_ = np.array(img,dtype=np.float32)\n",
    "        in_ = in_[:,:,::-1]\n",
    "        in_ -= np.array((104.00698793,116.66876762,122.67891434))\n",
    "        in_ = in_.transpose((2,0,1))\n",
    "        deployed_net.blobs['data'].reshape(1, *in_.shape)\n",
    "        deployed_net.blobs['data'].data[...] = in_\n",
    "        deployed_net.forward()\n",
    "        out_probs = deployed_net.blobs['prob'].data[...]\n",
    "        out = out_probs[:,:].argmax(axis=1)\n",
    "        print 'Possible labels', out\n",
    "        dic = {1:'sunset',0:'nonsunset'}\n",
    "        print 'Classification result: ',dic[int(np.unique(out))]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "** To make computation, plotting, and false positive/negative extraction easier, I directly used the test net .prototxt file instead of using the deploy.prototxt. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import caffe\n",
    "from sklearn.metrics import confusion_matrix\n",
    "test_net = caffe.Net(nets_root+'/my_sunset_net_test_cmdline.prototxt',\n",
    "                    nets_root+'/my_sunset_net_cmdline_iter_300.caffemodel'\n",
    "                    ,caffe.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "y_true=np.zeros(1)\n",
    "y_test=np.zeros(1)\n",
    "for iter in range(20):\n",
    "    test_net.forward()\n",
    "    y_true = np.hstack([y_true,test_net.blobs['label'].data])\n",
    "    y_test = np.hstack([y_test,test_net.blobs['probs'].data.argmax(1)])\n",
    "y_true=y_true[1:]\n",
    "y_test=y_test[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_true=np.array(y_true).flatten()\n",
    "y_test=np.array(y_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(y_true, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "imgplot = plt.imshow(conf_mat,cmap='YlOrRd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# False positives and False negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f_pos = []\n",
    "f_neg = []\n",
    "for i in range (10):\n",
    "    test_net.forward()\n",
    "    diff = test_net.blobs['label'].data - test_net.blobs['probs'].data.argmax(1)\n",
    "    f_pos_inds = np.where(diff == -1)\n",
    "    f_neg_inds = np.where(diff == 1)\n",
    "    \n",
    "    try:\n",
    "        if ((f_pos_inds[0]>=0)[0]):\n",
    "            f_pos.append(test_net.blobs['data'].data[f_pos_inds])\n",
    "        print 'Adding false positives'\n",
    "    except IndexError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        if ((f_neg_inds[0]>=0)[0]):\n",
    "            f_neg.append(test_net.blobs['data'].data[f_neg_inds])\n",
    "        print 'Adding false negatives'\n",
    "    except IndexError:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for j in range (len(f_pos)):\n",
    "    for k in range (f_pos[j].shape[0]):\n",
    "        im = np.zeros((256,256,3))\n",
    "        im[:,:,0]=f_pos[j][k][0]\n",
    "        im[:,:,1]=f_pos[j][k][1]\n",
    "        im[:,:,2]=f_pos[j][k][2]\n",
    "        plt.title(\"False Postive: nonsunset misclassified as sunset\")\n",
    "        plt.imshow(im.astype('uint16'),cmap='jet')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for l in range (len(f_neg)):\n",
    "    for m in range (f_neg[l].shape[0]):\n",
    "        im = np.zeros((256,256,3))\n",
    "        im[:,:,0]=f_neg[l][m][0]\n",
    "        im[:,:,1]=f_neg[l][m][1]\n",
    "        im[:,:,2]=f_neg[l][m][2]\n",
    "        plt.title(\"False Negative: sunset misclassified as nonsunset\")\n",
    "        plt.imshow(im.astype('uint16'))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Comment **\n",
    "\n",
    "As shown above, most false positive images have the sun being blocked. And most false negative images have simple compositions like sunset scenes: horizontal lines, wide color patches, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the sunset_net with Augmented Images\n",
    "\n",
    "My strategy toward data recomposition/augmentation is as follows: (All image augmenting is done by the Python script I wrote: ~/code/python_code/image_aug.py)\n",
    "\n",
    "In addition to the original training dataset, 499 images, I added 499 times 4 = 1996 images to the training set by:\n",
    "\n",
    "- Mirroring: I mannually generated mirror images for all 499 original training images and added to the new dataset which I called Train_aug, aug for augmented. \n",
    "\n",
    "- Cropping: I mannually cropped out four sides of each image by taking 10% amount of the pixels on the shorter side. This helps focusing on the sun object in each image. Then I added 499 cropped images to the original dataset as well. \n",
    "\n",
    "- Color enhancing: I enhanced the color and contrast by a factor of 1.25 for all images. \n",
    "\n",
    "- Hue: I also converted RGB original images into HSV images, hoping adding Hue would help. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_net_path_aug = sunset_helper_aug.sunset_net(sunset_lmdb,250,train=True)\n",
    "test_net_path_aug = sunset_helper_aug.sunset_net(sunset_lmdb,50,train=False)\n",
    "sunset_solver_filename_aug = sunset_helper_aug.solver(train_net_path_aug, test_net_path=test_net_path_aug, \n",
    "                                             displayFreq=5,test_interval=5,stepsize=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Solver: \", sunset_solver_filename_aug\n",
    "print \"Train: \", train_net_path_aug\n",
    "print \"Test: \", test_net_path_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show a few augmented images\n",
    "I will show below different kinds of augmented images I generated as examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "original_path ='/Users/tianchuliang/Documents/Projects/my_sunset_net/my_sunset_net/data/Train_aug/sunset/sunset_train_00068.jpg'\n",
    "mirror_path = '/Users/tianchuliang/Documents/Projects/my_sunset_net/my_sunset_net/data/Train_aug/sunset/mirrored_68.jpg'\n",
    "crop_path = '/Users/tianchuliang/Documents/Projects/my_sunset_net/my_sunset_net/data/Train_aug/sunset/center_cropped_68.jpg'\n",
    "color_path = '/Users/tianchuliang/Documents/Projects/my_sunset_net/my_sunset_net/data/Train_aug/sunset/enhanced_68.jpg'\n",
    "hue_path ='/Users/tianchuliang/Documents/Projects/my_sunset_net/my_sunset_net/data/Train_aug/sunset/hue_converted_68.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = mpimg.imread(original_path)\n",
    "plt.title('Original Image')\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "image = mpimg.imread(mirror_path)\n",
    "plt.title('Mirrored Image')\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "image = mpimg.imread(crop_path)\n",
    "plt.title('Cropped Image')\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "image = mpimg.imread(color_path)\n",
    "plt.title('Color Enhanced Image')\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "image = mpimg.imread(hue_path)\n",
    "plt.title('Hue Transformed Image')\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solver prototxt file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat /Users/tianchuliang/Documents/Projects/my_sunset_net/my_sunset_net/net/my_sunset_net_solver_aug_cmdline.prototxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train prototxt file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat /Users/tianchuliang/Documents/Projects/my_sunset_net/my_sunset_net/net/my_sunset_net_train_aug_cmdline.prototxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test prototxt file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat /Users/tianchuliang/Documents/Projects/my_sunset_net/my_sunset_net/net/my_sunset_net_test_aug_cmdline.prototxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(code_root+'/bash')\n",
    "os.system('chmod +x split_log_file_aug.sh')\n",
    "os.system('./split_log_file_aug.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_log_file = nets_root+'/my_sunset_net_aug_cmdline.log.train'\n",
    "test_log_file = nets_root+'/my_sunset_net_aug_cmdline.log.test'\n",
    "train_iters,train_loss,train_acc=log_parser.parse_train(train_log_file)\n",
    "test_iters,test_loss,test_acc=log_parser.parse_test(test_log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.title('Taining loss and accuracy over iterations')\n",
    "plt.xlabel('Number of iterations divided by 5')\n",
    "plt.ylabel('loss/accuracy')\n",
    "plt.plot(train_loss)\n",
    "plt.plot(train_acc)\n",
    "plt.legend(['Train loss','Train accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.title('Testing loss and accuracy over iterations')\n",
    "plt.xlabel('Number of iterations divided by 5')\n",
    "plt.ylabel('loss/accuracy')\n",
    "plt.plot(test_loss)\n",
    "plt.plot(test_acc)\n",
    "plt.legend(['Test loss','Test accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import caffe\n",
    "from sklearn.metrics import confusion_matrix\n",
    "test_net_aug = caffe.Net(nets_root+'/my_sunset_net_test_aug_cmdline.prototxt',\n",
    "                    nets_root+'/my_sunset_net_aug_cmdline_iter_300.caffemodel'\n",
    "                    ,caffe.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_true=np.zeros(1)\n",
    "y_test=np.zeros(1)\n",
    "for iter in range(20):\n",
    "    test_net_aug.forward()\n",
    "    y_true = np.hstack([y_true,test_net_aug.blobs['label'].data])\n",
    "    y_test = np.hstack([y_test,test_net_aug.blobs['probs'].data.argmax(1)])\n",
    "y_true=y_true[1:]\n",
    "y_test=y_test[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true=np.array(y_true).flatten()\n",
    "y_test=np.array(y_test).flatten()\n",
    "conf_mat = confusion_matrix(y_true, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "imgplot = plt.imshow(conf_mat,cmap='YlOrRd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# False positives and False negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_pos = []\n",
    "f_neg = []\n",
    "for i in range (10):\n",
    "    test_net_aug.forward()\n",
    "    diff = test_net_aug.blobs['label'].data - test_net_aug.blobs['probs'].data.argmax(1)\n",
    "    f_pos_inds = np.where(diff == -1)\n",
    "    f_neg_inds = np.where(diff == 1)\n",
    "    \n",
    "    try:\n",
    "        if ((f_pos_inds[0]>=0)[0]):\n",
    "            f_pos.append(test_net_aug.blobs['data'].data[f_pos_inds])\n",
    "        print 'Adding false positives'\n",
    "    except IndexError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        if ((f_neg_inds[0]>=0)[0]):\n",
    "            f_neg.append(test_net_aug.blobs['data'].data[f_neg_inds])\n",
    "        print 'Adding false negatives'\n",
    "    except IndexError:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for j in range (len(f_pos)):\n",
    "    for k in range (f_pos[j].shape[0]):\n",
    "        im = np.zeros((256,256,3))\n",
    "        im[:,:,0]=f_pos[j][k][0]\n",
    "        im[:,:,1]=f_pos[j][k][1]\n",
    "        im[:,:,2]=f_pos[j][k][2]\n",
    "        plt.title(\"False Postive: nonsunset misclassified as sunset\")\n",
    "        plt.imshow(im.astype('uint16'),cmap='jet')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for l in range (len(f_neg)):\n",
    "    for m in range (f_neg[l].shape[0]):\n",
    "        im = np.zeros((256,256,3))\n",
    "        im[:,:,0]=f_neg[l][m][0]\n",
    "        im[:,:,1]=f_neg[l][m][1]\n",
    "        im[:,:,2]=f_neg[l][m][2]\n",
    "        plt.title(\"False Negative: sunset misclassified as nonsunset\")\n",
    "        plt.imshow(im.astype('uint16'))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis:\n",
    "** Why doesn't augmented training data improve the classifier? **\n",
    "\n",
    "As shown above, the network trained on the augment data DOES NOT beat the previous one, which is trained on vanilla sunset images. In fact, given more data (original data added with augmented images), the second network actually produced more false positives and false negatives. \n",
    "\n",
    "Looking at false positivies and false negatives, we can see that the second model doesn't recognize well the obstructed sunset images, i.e blocked by buildings, trees, unbrellas, etc. \n",
    "\n",
    "The second model also tend to classify mountains falsely as sunset; this may be due to the compostion of mountains is similar to that of sunsets: large panel of color, horizontal lines, etc. \n",
    "\n",
    "I think the main reason augmenting data didn't improve second model much is because I directly added augmented images into the original dataset. ** This brought noise to the training data, and somewhat blinded the network during training. ** This is especially true since I directly mixed original data with color enhanced and Hue added images. \n",
    "\n",
    "A possible way to improve is: ** instead of mixing all images together, separate color enhanced, and hue added images as a separate training set**; these color-modified images tend to noisify the training. So, train separately on these data might be a better idea. \n",
    "\n",
    "As for mirroed or cropped images, I think these helped training when mixed with original images. It added more variants to the training data without too much bringing too much noise. \n",
    "\n",
    "One intersting thing I noticed in both models, especially in the second one, is the flat region in both training/testing loss and accuracy plots. I am not sure why the network suddenly started to improve after 140 iterations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
